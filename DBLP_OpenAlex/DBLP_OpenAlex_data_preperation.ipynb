{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preperation DBLP to OpenAlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBLP Query selection \n",
    "**Purpose**\n",
    "This script extracts a balanced selection of 100 questions from the DBLP-QuAD dataset, ensuring that:\n",
    "\n",
    "- Only specific templates (TP01, TP02, etc.) are included, all questions which can also be answered with OpenAlex.\n",
    "- Questions from TP17 have a valid ORCID (fetched via the DBLP SPARQL endpoint). For those it makes sense to include the ORCID, for later creating promts including the ORCID for OpenAlex\n",
    "- Questions are evenly distributed among template IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching ORCID for author: https://dblp.org/pid/89/4335\n",
      "Fetching ORCID for author: https://dblp.org/pid/77/5249\n",
      "Fetching ORCID for author: https://dblp.org/pid/33/2148\n",
      "Fetching ORCID for author: https://dblp.org/pid/269/7922\n",
      "Fetching ORCID for author: https://dblp.org/pid/88/6436\n",
      "Fetching ORCID for author: https://dblp.org/pid/16/4029\n",
      "Fetching ORCID for author: https://dblp.org/pid/159/5093\n",
      "Fetching ORCID for author: https://dblp.org/pid/04/3170\n",
      "Fetching ORCID for author: https://dblp.org/pid/126/0296\n",
      "Fetching ORCID for author: https://dblp.org/pid/06/3884\n",
      "Fetching ORCID for author: https://dblp.org/pid/51/7361\n",
      "Fetching ORCID for author: https://dblp.org/pid/200/7948\n",
      "Fetching ORCID for author: https://dblp.org/pid/31/117\n",
      "Fetching ORCID for author: https://dblp.org/pid/18/6200\n",
      "Fetching ORCID for author: https://dblp.org/pid/38/10526\n",
      "Fetching ORCID for author: https://dblp.org/pid/98/7910\n",
      "Fetching ORCID for author: https://dblp.org/pid/73/7523\n",
      "Fetching ORCID for author: https://dblp.org/pid/40/160\n",
      "Fetching ORCID for author: https://dblp.org/pid/86/8870\n",
      "Fetching ORCID for author: https://dblp.org/pid/s/TSchwentick\n",
      "Fetching ORCID for author: https://dblp.org/pid/152/2974\n",
      "Fetching ORCID for author: https://dblp.org/pid/21/4409\n",
      "Fetching ORCID for author: https://dblp.org/pid/14/4350\n",
      "Fetching ORCID for author: https://dblp.org/pid/54/5244\n",
      "Fetching ORCID for author: https://dblp.org/pid/30/3110\n",
      "Fetching ORCID for author: https://dblp.org/pid/151/7017\n",
      "Fetching ORCID for author: https://dblp.org/pid/f/ThomasFevens\n",
      "Fetching ORCID for author: https://dblp.org/pid/91/5344\n",
      "Fetching ORCID for author: https://dblp.org/pid/68/11145\n",
      "Fetching ORCID for author: https://dblp.org/pid/151/0055\n",
      "Fetching ORCID for author: https://dblp.org/pid/53/2843\n",
      "Fetching ORCID for author: https://dblp.org/pid/28/5820\n",
      "Fetching ORCID for author: https://dblp.org/pid/241/9817\n",
      "Fetching ORCID for author: https://dblp.org/pid/62/2932-2\n",
      "Fetching ORCID for author: https://dblp.org/pid/210/2755\n",
      "Fetching ORCID for author: https://dblp.org/pid/f/StefanFunke\n",
      "Fetching ORCID for author: https://dblp.org/pid/06/1457\n",
      "Fetching ORCID for author: https://dblp.org/pid/00/1901\n",
      "Fetching ORCID for author: https://dblp.org/pid/62/1791\n",
      "Fetching ORCID for author: https://dblp.org/pid/w/AnnikaWarn\n",
      "Fetching ORCID for author: https://dblp.org/pid/21/10960\n",
      "Fetching ORCID for author: https://dblp.org/pid/298/6506\n",
      "Fetching ORCID for author: https://dblp.org/pid/64/1130\n",
      "Fetching ORCID for author: https://dblp.org/pid/212/6375\n",
      "Fetching ORCID for author: https://dblp.org/pid/44/1169\n",
      "Fetching ORCID for author: https://dblp.org/pid/27/829\n",
      "Fetching ORCID for author: https://dblp.org/pid/74/1222\n",
      "Fetching ORCID for author: https://dblp.org/pid/r/RAdaLuzReis\n",
      "Fetching ORCID for author: https://dblp.org/pid/32/4660\n",
      "Fetching ORCID for author: https://dblp.org/pid/182/1623\n",
      "Fetching ORCID for author: https://dblp.org/pid/30/2301\n",
      "Fetching ORCID for author: https://dblp.org/pid/90/187\n",
      "Fetching ORCID for author: https://dblp.org/pid/02/1412\n",
      "Fetching ORCID for author: https://dblp.org/pid/15/7004\n",
      "Fetching ORCID for author: https://dblp.org/pid/83/8389\n",
      "Fetching ORCID for author: https://dblp.org/pid/198/2061\n",
      "Fetching ORCID for author: https://dblp.org/pid/319/1362\n",
      "Fetching ORCID for author: https://dblp.org/pid/25/2049\n",
      "Fetching ORCID for author: https://dblp.org/pid/48/195-1\n",
      "Fetching ORCID for author: https://dblp.org/pid/65/6264\n",
      "Fetching ORCID for author: https://dblp.org/pid/60/6657\n",
      "Fetching ORCID for author: https://dblp.org/pid/48/1480\n",
      "Fetching ORCID for author: https://dblp.org/pid/160/6061\n",
      "Fetching ORCID for author: https://dblp.org/pid/32/6785\n",
      "Fetching ORCID for author: https://dblp.org/pid/190/3350\n",
      "Fetching ORCID for author: https://dblp.org/pid/74/11536\n",
      "Fetching ORCID for author: https://dblp.org/pid/156/0484\n",
      "Fetching ORCID for author: https://dblp.org/pid/144/9533\n",
      "Fetching ORCID for author: https://dblp.org/pid/c/RChandrasekaran\n",
      "Fetching ORCID for author: https://dblp.org/pid/39/5181\n",
      "Fetching ORCID for author: https://dblp.org/pid/48/5039\n",
      "Fetching ORCID for author: https://dblp.org/pid/71/903\n",
      "Fetching ORCID for author: https://dblp.org/pid/66/2699\n",
      "\n",
      "Number of selected questions per template_id:\n",
      "TP01: 13\n",
      "TP02: 12\n",
      "TP03: 12\n",
      "TP05: 14\n",
      "TP12: 12\n",
      "TP17: 13\n",
      "TP34: 12\n",
      "TP52: 12\n",
      "\n",
      "Total selected questions: 100\n",
      "Saved selected questions to DBLP_100_questions.json\n"
     ]
    }
   ],
   "source": [
    "# URL of the JSON dataset\n",
    "url = \"https://raw.githubusercontent.com/awalesushil/DBLP-QuAD/refs/heads/main/data/DBLP-QuAD/train/questions.json\"\n",
    "\n",
    "# Define the SPARQL endpoint\n",
    "SPARQL_ENDPOINT = \"https://sparql.dblp.org/sparql\"\n",
    "\n",
    "# Fetch the JSON data from the URL\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# List of template_ids to filter\n",
    "template_ids = [\n",
    "    \"TP01\", \"TP02\", \"TP03\", \"TP05\", \"TP12\",\n",
    "    \"TP17\", \"TP34\", \"TP52\"\n",
    "]\n",
    "\n",
    "# Filter questions by the specified template_ids\n",
    "filtered_questions = {tid: [q for q in data[\"questions\"] if q[\"template_id\"] == tid] for tid in template_ids}\n",
    "\n",
    "# Function to query SPARQL endpoint for ORCID using full author URL\n",
    "def get_orcid_from_sparql(author_url):\n",
    "    query = f\"\"\"\n",
    "    SELECT ?orcid WHERE {{\n",
    "      <{author_url}> <https://dblp.org/rdf/schema#orcid> ?orcid\n",
    "    }}\n",
    "    \"\"\"\n",
    "    params = {\"query\": query, \"format\": \"json\"}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(SPARQL_ENDPOINT, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        # Extract ORCID if found\n",
    "        bindings = data.get(\"results\", {}).get(\"bindings\", [])\n",
    "        if bindings:\n",
    "            return bindings[0][\"orcid\"][\"value\"]\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error querying ORCID for {author_url}: {e}\")\n",
    "\n",
    "    return None  # Return None if ORCID is not found\n",
    "\n",
    "# Ensure TP17 questions have an ORCID\n",
    "valid_tp17_questions = []\n",
    "for question in filtered_questions[\"TP17\"]:\n",
    "    updated_entities = []\n",
    "    has_valid_orcid = False\n",
    "\n",
    "    for entity in question[\"entities\"]:\n",
    "        entity_clean = entity.replace(\"<\", \"\").replace(\">\", \"\")  # Remove < >\n",
    "        if \"/pid/\" in entity_clean:  # Identify author entities\n",
    "            print(f\"Fetching ORCID for author: {entity_clean}\")\n",
    "            orcid = get_orcid_from_sparql(entity_clean)\n",
    "\n",
    "            # If ORCID is found, mark as valid\n",
    "            if orcid:\n",
    "                has_valid_orcid = True\n",
    "\n",
    "            updated_entities.append({\"author\": entity, \"orcid\": orcid})\n",
    "            time.sleep(1)  # Prevent API rate limiting\n",
    "        else:\n",
    "            updated_entities.append({\"entity\": entity})  # Keep non-author entities unchanged\n",
    "\n",
    "    if has_valid_orcid:\n",
    "        question[\"entities\"] = updated_entities\n",
    "        valid_tp17_questions.append(question)\n",
    "\n",
    "# Replace old TP17 questions with only valid ones\n",
    "filtered_questions[\"TP17\"] = valid_tp17_questions\n",
    "\n",
    "# Determine the number of entries to select from each template_id\n",
    "num_entries_per_template = 100 // len(template_ids)\n",
    "\n",
    "# Dictionary to hold selected questions\n",
    "selected_questions = {tid: [] for tid in template_ids}\n",
    "\n",
    "# Randomly select questions for each template_id\n",
    "for tid in template_ids:\n",
    "    # Randomly sample required number of questions\n",
    "    selected_questions[tid] = random.sample(\n",
    "        filtered_questions[tid],\n",
    "        min(num_entries_per_template, len(filtered_questions[tid]))\n",
    "    )\n",
    "\n",
    "# Flatten the list of selected questions\n",
    "final_selection = [q for questions in selected_questions.values() for q in questions]\n",
    "\n",
    "# If the total number of selected questions is less than 100, sample additional questions\n",
    "if len(final_selection) < 100:\n",
    "    remaining_questions = [q for q in data[\"questions\"] if q not in final_selection and q[\"template_id\"] in template_ids]\n",
    "    additional_needed = 100 - len(final_selection)\n",
    "    final_selection.extend(random.sample(remaining_questions, min(additional_needed, len(remaining_questions))))\n",
    "\n",
    "final_selection = final_selection[:100]\n",
    "\n",
    "# Count the number of questions per template_id\n",
    "template_counts = {tid: 0 for tid in template_ids}\n",
    "for question in final_selection:\n",
    "    template_counts[question[\"template_id\"]] += 1\n",
    "\n",
    "# Print the counts per template_id\n",
    "print(\"\\nNumber of selected questions per template_id:\")\n",
    "for tid, count in sorted(template_counts.items()):\n",
    "    print(f\"{tid}: {count}\")\n",
    "\n",
    "# Create the final JSON structure\n",
    "final_data = {\"questions\": final_selection}\n",
    "\n",
    "# Save to a JSON file\n",
    "output_filename = \"DBLP_100_questions.json\"\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nTotal selected questions: {len(final_selection)}\")\n",
    "print(f\"Saved selected questions to {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose**\n",
    "The goal of this script is to execute SPARQL queries from DBLP_100_questions.json against the DBLP SPARQL endpoint and store the responses. This allows for:\n",
    "- Retrieving structured knowledge (e.g., authors, publications, venues) from DBLP.\n",
    "- Ensuring data completeness by associating each question with its corresponding SPARQL result.\n",
    "- Generating a structured dataset (DBLP_100_results.json) that combines questions and responses for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying Q3731...\n",
      "Querying Q3790...\n",
      "Querying Q3633...\n",
      "Querying Q3841...\n",
      "Querying Q3806...\n",
      "Querying Q3738...\n",
      "Querying Q3612...\n",
      "Querying Q3848...\n",
      "Querying Q3781...\n",
      "Querying Q3683...\n",
      "Querying Q3595...\n",
      "Querying Q3817...\n",
      "Querying Q3518...\n",
      "Querying Q3566...\n",
      "Querying Q3536...\n",
      "Querying Q3666...\n",
      "Querying Q3822...\n",
      "Querying Q3537...\n",
      "Querying Q3578...\n",
      "Querying Q3699...\n",
      "Querying Q3762...\n",
      "Querying Q3846...\n",
      "Querying Q3686...\n",
      "Querying Q3630...\n",
      "Querying Q3775...\n",
      "Querying Q3644...\n",
      "Querying Q3771...\n",
      "Querying Q3516...\n",
      "Querying Q3832...\n",
      "Querying Q3802...\n",
      "Querying Q3576...\n",
      "Querying Q3547...\n",
      "Querying Q3663...\n",
      "Querying Q3613...\n",
      "Querying Q3709...\n",
      "Querying Q3665...\n",
      "Querying Q3548...\n",
      "Querying Q3768...\n",
      "Querying Q3641...\n",
      "Querying Q3581...\n",
      "Querying Q3585...\n",
      "Querying Q3568...\n",
      "Querying Q3844...\n",
      "Querying Q3584...\n",
      "Querying Q3606...\n",
      "Querying Q3597...\n",
      "Querying Q3769...\n",
      "Querying Q3690...\n",
      "Querying Q3999...\n",
      "Querying Q3923...\n",
      "Querying Q4057...\n",
      "Querying Q4140...\n",
      "Querying Q3932...\n",
      "Querying Q3854...\n",
      "Querying Q3852...\n",
      "Querying Q3866...\n",
      "Querying Q3864...\n",
      "Querying Q4053...\n",
      "Querying Q3988...\n",
      "Querying Q4110...\n",
      "Querying Q3976...\n",
      "Querying Q4045...\n",
      "Querying Q4171...\n",
      "Querying Q4194...\n",
      "Querying Q3963...\n",
      "Querying Q4195...\n",
      "Querying Q4075...\n",
      "Querying Q4199...\n",
      "Querying Q4079...\n",
      "Querying Q4017...\n",
      "Querying Q3927...\n",
      "Querying Q3979...\n",
      "Querying Q4572...\n",
      "Querying Q4559...\n",
      "Querying Q4606...\n",
      "Querying Q4665...\n",
      "Querying Q4646...\n",
      "Querying Q4890...\n",
      "Querying Q4641...\n",
      "Querying Q4856...\n",
      "Querying Q4876...\n",
      "Querying Q4613...\n",
      "Querying Q4567...\n",
      "Querying Q4884...\n",
      "Querying Q5550...\n",
      "Querying Q5505...\n",
      "Querying Q5259...\n",
      "Querying Q5470...\n",
      "Querying Q5361...\n",
      "Querying Q5419...\n",
      "Querying Q5420...\n",
      "Querying Q5293...\n",
      "Querying Q5332...\n",
      "Querying Q5498...\n",
      "Querying Q5579...\n",
      "Querying Q5380...\n",
      "Querying Q3737...\n",
      "Querying Q3926...\n",
      "Querying Q3843...\n",
      "Querying Q3542...\n",
      "\n",
      "Saved query results to DBLP_100_results.json\n"
     ]
    }
   ],
   "source": [
    "# Load queries from the JSON file\n",
    "input_filename = \"DBLP_100_questions.json\"\n",
    "output_filename = \"DBLP_100_results.json\"\n",
    "\n",
    "with open(input_filename, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Iterate over each question and execute the SPARQL query\n",
    "for question in data[\"questions\"]:\n",
    "    query = question[\"query\"][\"sparql\"]  # Extract the SPARQL query\n",
    "    query_id = question[\"id\"]  # Get the question ID\n",
    "\n",
    "    # Define the request parameters\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "\n",
    "    print(f\"Querying {query_id}...\")\n",
    "\n",
    "    try:\n",
    "        # Send request to the DBLP SPARQL endpoint\n",
    "        response = requests.get(SPARQL_ENDPOINT, params=params, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        query_result = response.json()\n",
    "\n",
    "        # Store the original question along with the response\n",
    "        question_with_response = question.copy()  # Preserve all original fields\n",
    "        question_with_response[\"response\"] = query_result  # Add API response\n",
    "\n",
    "        results.append(question_with_response)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error querying {query_id}: {e}\")\n",
    "\n",
    "        # Store the original question along with the error message\n",
    "        question_with_response = question.copy()\n",
    "        question_with_response[\"response\"] = {\"error\": str(e)}\n",
    "\n",
    "        results.append(question_with_response)\n",
    "\n",
    "# Save the results to a JSON file\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"questions\": results}, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nSaved query results to {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Steps: \n",
    "- Query the queries in OpenAlex and get the corresponding results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
