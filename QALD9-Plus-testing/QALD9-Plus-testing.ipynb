{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating DBpedia queries to Wikidata with LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the necessary libraries\n",
    "import re\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset for asking the LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dataset saved to 'llm_input_dataset.json'.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from 100_complete_entries.json\n",
    "with open(\"100_complete_entries.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Create input dataset for the LLM\n",
    "llm_inputs = []\n",
    "\n",
    "for entry in data:\n",
    "    # Extract required fields\n",
    "    question = entry.get(\"question\", \"\")  # Natural language question\n",
    "    dbpedia_query = entry.get(\"dbpedia_query\", \"\")  # SPARQL query for DBpedia\n",
    "    \n",
    "    # Extract entities and relations (ER2) in Wikidata\n",
    "    er2 = [\n",
    "        {\n",
    "            \"dbpedia_id\": er[\"dbpedia_id\"],\n",
    "            \"wikidata_ids\": er[\"wikidata_ids\"]\n",
    "        }\n",
    "        for er in entry.get(\"mapped_entities_relations\", {}).get(\"entities_relations\", [])\n",
    "        if er[\"wikidata_ids\"]  # Only include non-empty Wikidata mappings\n",
    "    ]\n",
    "    \n",
    "    # Skip if there are no valid Wikidata mappings\n",
    "    if not er2:\n",
    "        continue\n",
    "\n",
    "    # Construct the input for the LLM\n",
    "    llm_input = {\n",
    "        \"context\": {\n",
    "            \"natural_language_question\": question,\n",
    "            \"sparql_query_kg1\": dbpedia_query,\n",
    "            \"kg1_name\": \"DBpedia\",\n",
    "            \"kg2_name\": \"Wikidata\",\n",
    "            \"er2\": er2,\n",
    "            \"instruction\": \"Given the information above, produce a SPARQL query for KG2.\"\n",
    "        }\n",
    "    }\n",
    "    llm_inputs.append(llm_input)\n",
    "\n",
    "# Save the processed dataset to a new JSON file\n",
    "with open(\"llm_input_dataset.json\", \"w\") as file:\n",
    "    json.dump(llm_inputs, file, indent=4)\n",
    "\n",
    "print(f\"Processed dataset saved to 'llm_input_dataset.json'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating second version of llm input dataset\n",
    "This version includes an output template in the instruction in order to make it easier to extract the final SPARQL query from the output of the LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dataset saved to 'llm_input_dataset_template.json'.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from 100_complete_entries.json\n",
    "with open(\"100_complete_entries.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Create input dataset for the LLM\n",
    "llm_inputs = []\n",
    "\n",
    "for entry in data:\n",
    "    # Extract required fields\n",
    "    question = entry.get(\"question\", \"\")  # Natural language question\n",
    "    dbpedia_query = entry.get(\"dbpedia_query\", \"\")  # SPARQL query for DBpedia\n",
    "    \n",
    "    # Extract entities and relations (ER2) in Wikidata\n",
    "    er2 = [\n",
    "        {\n",
    "            \"dbpedia_id\": er[\"dbpedia_id\"],\n",
    "            \"wikidata_ids\": er[\"wikidata_ids\"]\n",
    "        }\n",
    "        for er in entry.get(\"mapped_entities_relations\", {}).get(\"entities_relations\", [])\n",
    "        if er[\"wikidata_ids\"]  # Only include non-empty Wikidata mappings\n",
    "    ]\n",
    "    \n",
    "    # Skip if there are no valid Wikidata mappings\n",
    "    if not er2:\n",
    "        continue\n",
    "\n",
    "    # Construct the input for the LLM\n",
    "    llm_input = {\n",
    "        \"context\": {\n",
    "            \"natural_language_question\": question,\n",
    "            \"sparql_query_kg1\": dbpedia_query,\n",
    "            \"kg1_name\": \"DBpedia\",\n",
    "            \"kg2_name\": \"Wikidata\",\n",
    "            \"er2\": er2,\n",
    "            \"instruction\": \"Given the information above, produce a SPARQL query for KG2. In your answer please hightlight the final, complete SPARQL query within the tags <sparql> and </sparql>.\"\n",
    "        }\n",
    "    }\n",
    "    llm_inputs.append(llm_input)\n",
    "\n",
    "# Save the processed dataset to a new JSON file\n",
    "with open(\"llm_input_dataset_template.json\", \"w\") as file:\n",
    "    json.dump(llm_inputs, file, indent=4)\n",
    "\n",
    "print(f\"Processed dataset saved to 'llm_input_dataset_template.json'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First test with 10 sample queries\n",
    "Using meta-llama-3.1-8b-instruct for the first test of translating the queries from DBpedia to Wikidata. The connection works and the model is able to translate the queries. The output is quite large, because the model also explains what as been done. Should the prompt be changed to get a more concise output, only the complete query?\n",
    "\n",
    "**meta-llama-3.1-8b-instruct is the smallest available model at Academic Cloud https://chat-ai.academiccloud.de/chat, with 8billion parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated SPARQL queries for 10 questions saved to 'translated_llm_output_10_queries.json'.\n"
     ]
    }
   ],
   "source": [
    "# Set up the LLM API connection\n",
    "api_key = '###'\n",
    "base_url = \"https://chat-ai.academiccloud.de/v1\"\n",
    "model = \"meta-llama-3.1-8b-instruct\"  # Replace with the appropriate model\n",
    "\n",
    "# Start OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "# Load the input dataset\n",
    "with open(\"llm_input_dataset.json\", \"r\") as file:\n",
    "    llm_input_data = json.load(file)\n",
    "\n",
    "# Initialize the list to store the responses\n",
    "translated_dataset = []\n",
    "\n",
    "# Limit to the first 10 queries\n",
    "limited_input_data = llm_input_data[:10]\n",
    "\n",
    "# Query the LLM for each entry in the limited dataset\n",
    "for entry in limited_input_data:\n",
    "    context = entry[\"context\"]\n",
    "    \n",
    "    # Create the prompt for the LLM\n",
    "    prompt = (\n",
    "        f\"Context:\\n\"\n",
    "        f\"Natural Language Question: {context['natural_language_question']}\\n\"\n",
    "        f\"SPARQL Query for KG1 ({context['kg1_name']}):\\n\"\n",
    "        f\"{context['sparql_query_kg1']}\\n\"\n",
    "        f\"Knowledge Graph 1 Name: {context['kg1_name']}\\n\"\n",
    "        f\"Knowledge Graph 2 Name: {context['kg2_name']}\\n\"\n",
    "        f\"Entity and Relation Mapping (ER2):\\n{json.dumps(context['er2'], indent=2)}\\n\"\n",
    "        f\"Instruction: {context['instruction']}\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Query the LLM\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            model=model\n",
    "        )\n",
    "        \n",
    "        # Extract the generated SPARQL query from the response\n",
    "        response_text = response.choices[0].message.content\n",
    "        \n",
    "        # Append the response to the translated dataset\n",
    "        translated_entry = {\n",
    "            \"context\": context,\n",
    "            \"sparql_query_kg2\": response_text  # Add the translated SPARQL query\n",
    "        }\n",
    "        translated_dataset.append(translated_entry)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error querying LLM for question ID {context.get('natural_language_question', 'unknown')}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Save the translated dataset to a new JSON file\n",
    "with open(\"translated_llm_output_10_queries_meta-llama-3.1-8b.json\", \"w\") as file:\n",
    "    json.dump(translated_dataset, file, indent=4)\n",
    "\n",
    "print(\"Translated SPARQL queries for 10 questions saved to 'translated_llm_output_10_queries_meta-llama-3.1-8b.json'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for Mistral-Large-Instruct \n",
    "The model includes 123billion parameters and is the largest available model at Academic Cloud https://chat-ai.academiccloud.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated SPARQL queries for 10 questions saved to 'translated_llm_output_10_queries_mistral.json'.\n"
     ]
    }
   ],
   "source": [
    "# Set up the LLM API connection\n",
    "api_key = '###'\n",
    "base_url = \"https://chat-ai.academiccloud.de/v1\"\n",
    "model = \"mistral-large-instruct\"  # Updated to use the new model\n",
    "\n",
    "# Start OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "# Load the input dataset\n",
    "with open(\"llm_input_dataset.json\", \"r\") as file:\n",
    "    llm_input_data = json.load(file)\n",
    "\n",
    "# Initialize the list to store the responses\n",
    "translated_dataset = []\n",
    "\n",
    "# Limit to the first 10 queries\n",
    "limited_input_data = llm_input_data[:10]\n",
    "\n",
    "# Query the LLM for each entry in the limited dataset\n",
    "for entry in limited_input_data:\n",
    "    context = entry[\"context\"]\n",
    "    \n",
    "    # Create the prompt for the LLM\n",
    "    prompt = (\n",
    "        f\"Context:\\n\"\n",
    "        f\"Natural Language Question: {context['natural_language_question']}\\n\"\n",
    "        f\"SPARQL Query for KG1 ({context['kg1_name']}):\\n\"\n",
    "        f\"{context['sparql_query_kg1']}\\n\"\n",
    "        f\"Knowledge Graph 1 Name: {context['kg1_name']}\\n\"\n",
    "        f\"Knowledge Graph 2 Name: {context['kg2_name']}\\n\"\n",
    "        f\"Entity and Relation Mapping (ER2):\\n{json.dumps(context['er2'], indent=2)}\\n\"\n",
    "        f\"Instruction: {context['instruction']}\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Query the LLM\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            model=model\n",
    "        )\n",
    "        \n",
    "        # Extract the generated SPARQL query from the response\n",
    "        response_text = response.choices[0].message.content\n",
    "        \n",
    "        # Append the response to the translated dataset\n",
    "        translated_entry = {\n",
    "            \"context\": context,\n",
    "            \"sparql_query_kg2\": response_text  # Add the translated SPARQL query\n",
    "        }\n",
    "        translated_dataset.append(translated_entry)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error querying LLM for question ID {context.get('natural_language_question', 'unknown')}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Save the translated dataset to a new JSON file\n",
    "with open(\"translated_llm_output_10_queries_mistral.json\", \"w\") as file:\n",
    "    json.dump(translated_dataset, file, indent=4)\n",
    "\n",
    "print(\"Translated SPARQL queries for 10 questions saved to 'translated_llm_output_10_queries_mistral.json'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing meta-llama-3.1-8b-instruct with 100 queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated SPARQL queries for all questions saved to 'translated_llm_output_meta-llama-3.1-8b.json'.\n"
     ]
    }
   ],
   "source": [
    "# Set up the LLM API connection\n",
    "api_key = '###'\n",
    "base_url = \"https://chat-ai.academiccloud.de/v1\"\n",
    "model = \"meta-llama-3.1-8b-instruct\"  # Replace with the appropriate model\n",
    "\n",
    "# Start OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "# Load the input dataset\n",
    "with open(\"llm_input_dataset.json\", \"r\") as file:\n",
    "    llm_input_data = json.load(file)\n",
    "\n",
    "# Initialize the list to store the responses\n",
    "translated_dataset = []\n",
    "\n",
    "# Query the LLM for each entry in the dataset\n",
    "for entry in llm_input_data:\n",
    "    context = entry[\"context\"]\n",
    "    \n",
    "    # Create the prompt for the LLM\n",
    "    prompt = (\n",
    "        f\"Context:\\n\"\n",
    "        f\"Natural Language Question: {context['natural_language_question']}\\n\"\n",
    "        f\"SPARQL Query for KG1 ({context['kg1_name']}):\\n\"\n",
    "        f\"{context['sparql_query_kg1']}\\n\"\n",
    "        f\"Knowledge Graph 1 Name: {context['kg1_name']}\\n\"\n",
    "        f\"Knowledge Graph 2 Name: {context['kg2_name']}\\n\"\n",
    "        f\"Entity and Relation Mapping (ER2):\\n{json.dumps(context['er2'], indent=2)}\\n\"\n",
    "        f\"Instruction: {context['instruction']}\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Query the LLM\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            model=model\n",
    "        )\n",
    "        \n",
    "        # Extract the generated SPARQL query from the response\n",
    "        response_text = response.choices[0].message.content\n",
    "        \n",
    "        # Append the response to the translated dataset\n",
    "        translated_entry = {\n",
    "            \"context\": context,\n",
    "            \"sparql_query_kg2\": response_text  # Add the translated SPARQL query\n",
    "        }\n",
    "        translated_dataset.append(translated_entry)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error querying LLM for question ID {context.get('natural_language_question', 'unknown')}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Save the translated dataset to a new JSON file\n",
    "with open(\"translated_llm_output_meta-llama-3.1-8b.json\", \"w\") as file:\n",
    "    json.dump(translated_dataset, file, indent=4)\n",
    "\n",
    "print(\"Translated SPARQL queries for all questions saved to 'translated_llm_output_meta-llama-3.1-8b.json'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Mistral-Large-instruct with 100 queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated SPARQL queries for all questions saved to 'translated_llm_output_mistral.json'.\n"
     ]
    }
   ],
   "source": [
    "# Set up the LLM API connection\n",
    "api_key = '###'\n",
    "base_url = \"https://chat-ai.academiccloud.de/v1\"\n",
    "model = \"mistral-large-instruct\"\n",
    "\n",
    "# Start OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "# Load the input dataset\n",
    "with open(\"llm_input_dataset.json\", \"r\") as file:\n",
    "    llm_input_data = json.load(file)\n",
    "\n",
    "# Initialize the list to store the responses\n",
    "translated_dataset = []\n",
    "\n",
    "# Query the LLM for each entry in the dataset\n",
    "for entry in llm_input_data:\n",
    "    context = entry[\"context\"]\n",
    "    \n",
    "    # Create the prompt for the LLM\n",
    "    prompt = (\n",
    "        f\"Context:\\n\"\n",
    "        f\"Natural Language Question: {context['natural_language_question']}\\n\"\n",
    "        f\"SPARQL Query for KG1 ({context['kg1_name']}):\\n\"\n",
    "        f\"{context['sparql_query_kg1']}\\n\"\n",
    "        f\"Knowledge Graph 1 Name: {context['kg1_name']}\\n\"\n",
    "        f\"Knowledge Graph 2 Name: {context['kg2_name']}\\n\"\n",
    "        f\"Entity and Relation Mapping (ER2):\\n{json.dumps(context['er2'], indent=2)}\\n\"\n",
    "        f\"Instruction: {context['instruction']}\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Query the LLM\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            model=model\n",
    "        )\n",
    "        \n",
    "        # Extract the generated SPARQL query from the response\n",
    "        response_text = response.choices[0].message.content\n",
    "        \n",
    "        # Append the response to the translated dataset\n",
    "        translated_entry = {\n",
    "            \"context\": context,\n",
    "            \"sparql_query_kg2\": response_text  # Add the translated SPARQL query\n",
    "        }\n",
    "        translated_dataset.append(translated_entry)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error querying LLM for question ID {context.get('natural_language_question', 'unknown')}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Save the translated dataset to a new JSON file\n",
    "with open(\"translated_llm_output_mistral.json\", \"w\") as file:\n",
    "    json.dump(translated_dataset, file, indent=4)\n",
    "\n",
    "print(\"Translated SPARQL queries for all questions saved to 'translated_llm_output_mistral.json'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing meta-llama-3.1-8b-instruct with 100 queries and the updated query template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated SPARQL queries for all questions saved to 'translated_llm_output_meta-llama-3.1-8b_template.json'.\n"
     ]
    }
   ],
   "source": [
    "# Set up the LLM API connection\n",
    "api_key = '###'\n",
    "base_url = \"https://chat-ai.academiccloud.de/v1\"\n",
    "model = \"meta-llama-3.1-8b-instruct\"  # Replace with the appropriate model\n",
    "\n",
    "# Start OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "# Load the input dataset\n",
    "with open(\"llm_input_dataset_template.json\", \"r\") as file:\n",
    "    llm_input_data = json.load(file)\n",
    "\n",
    "# Initialize the list to store the responses\n",
    "translated_dataset = []\n",
    "\n",
    "# Query the LLM for each entry in the dataset\n",
    "for entry in llm_input_data:\n",
    "    context = entry[\"context\"]\n",
    "    \n",
    "    # Create the prompt for the LLM\n",
    "    prompt = (\n",
    "        f\"Context:\\n\"\n",
    "        f\"Natural Language Question: {context['natural_language_question']}\\n\"\n",
    "        f\"SPARQL Query for KG1 ({context['kg1_name']}):\\n\"\n",
    "        f\"{context['sparql_query_kg1']}\\n\"\n",
    "        f\"Knowledge Graph 1 Name: {context['kg1_name']}\\n\"\n",
    "        f\"Knowledge Graph 2 Name: {context['kg2_name']}\\n\"\n",
    "        f\"Entity and Relation Mapping (ER2):\\n{json.dumps(context['er2'], indent=2)}\\n\"\n",
    "        f\"Instruction: {context['instruction']}\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Query the LLM\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            model=model\n",
    "        )\n",
    "        \n",
    "        # Extract the generated SPARQL query from the response\n",
    "        response_text = response.choices[0].message.content\n",
    "        \n",
    "        # Append the response to the translated dataset\n",
    "        translated_entry = {\n",
    "            \"context\": context,\n",
    "            \"sparql_query_kg2\": response_text  # Add the translated SPARQL query\n",
    "        }\n",
    "        translated_dataset.append(translated_entry)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error querying LLM for question ID {context.get('natural_language_question', 'unknown')}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Save the translated dataset to a new JSON file\n",
    "with open(\"translated_llm_output_meta-llama-3.1-8b_template.json\", \"w\") as file:\n",
    "    json.dump(translated_dataset, file, indent=4)\n",
    "\n",
    "print(\"Translated SPARQL queries for all questions saved to 'translated_llm_output_meta-llama-3.1-8b_template.json'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Mistral-Large-instruct with 100 queries and the updated query template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error querying LLM for question ID What is the alma mater of the chancellor of Germany Angela Merkel?: Error code: 429 - {'message': 'API rate limit exceeded', 'request_id': '5123895c32290a294e6b6d54c3a85b52'}\n",
      "Error querying LLM for question ID Who created Goofy?: Error code: 429 - {'message': 'API rate limit exceeded', 'request_id': '4addf6380917171023864136e8287f11'}\n",
      "Translated SPARQL queries for all questions saved to 'translated_llm_output_mistral_template.json'.\n"
     ]
    }
   ],
   "source": [
    "# Set up the LLM API connection\n",
    "api_key = '###'\n",
    "base_url = \"https://chat-ai.academiccloud.de/v1\"\n",
    "model = \"mistral-large-instruct\"\n",
    "\n",
    "# Start OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "# Load the input dataset\n",
    "with open(\"llm_input_dataset_template.json\", \"r\") as file:\n",
    "    llm_input_data = json.load(file)\n",
    "\n",
    "# Initialize the list to store the responses\n",
    "translated_dataset = []\n",
    "\n",
    "# Query the LLM for each entry in the dataset\n",
    "for entry in llm_input_data:\n",
    "    context = entry[\"context\"]\n",
    "    \n",
    "    # Create the prompt for the LLM\n",
    "    prompt = (\n",
    "        f\"Context:\\n\"\n",
    "        f\"Natural Language Question: {context['natural_language_question']}\\n\"\n",
    "        f\"SPARQL Query for KG1 ({context['kg1_name']}):\\n\"\n",
    "        f\"{context['sparql_query_kg1']}\\n\"\n",
    "        f\"Knowledge Graph 1 Name: {context['kg1_name']}\\n\"\n",
    "        f\"Knowledge Graph 2 Name: {context['kg2_name']}\\n\"\n",
    "        f\"Entity and Relation Mapping (ER2):\\n{json.dumps(context['er2'], indent=2)}\\n\"\n",
    "        f\"Instruction: {context['instruction']}\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # Query the LLM\n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            model=model\n",
    "        )\n",
    "        \n",
    "        # Extract the generated SPARQL query from the response\n",
    "        response_text = response.choices[0].message.content\n",
    "        \n",
    "        # Append the response to the translated dataset\n",
    "        translated_entry = {\n",
    "            \"context\": context,\n",
    "            \"sparql_query_kg2\": response_text  # Add the translated SPARQL query\n",
    "        }\n",
    "        translated_dataset.append(translated_entry)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error querying LLM for question ID {context.get('natural_language_question', 'unknown')}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Save the translated dataset to a new JSON file\n",
    "with open(\"translated_llm_output_mistral_template.json\", \"w\") as file:\n",
    "    json.dump(translated_dataset, file, indent=4)\n",
    "\n",
    "print(\"Translated SPARQL queries for all questions saved to 'translated_llm_output_mistral_template.json'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the results\n",
    "For now it can be seen that the extraction process for the larger model (mistral-large-instruct) is working better than for the smaller model (meta-llama-3.1-8b-instruct). The output of the smaller model is not that structured making it harder to extract the queries. On the first sight it also seems that the queries from the larger model are working better.\n",
    "\n",
    "\n",
    "Extracting the SPARQL queries from LLM output for **mistral-large-instruct**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and extracted data has been saved to mistral_wiki_trans_sparql_queries.json.\n"
     ]
    }
   ],
   "source": [
    "# Load the input JSON file\n",
    "file_path = \"translated_llm_output_mistral.json\"\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Function to extract SPARQL query from the `sparql_query_kg2` field and remove comments\n",
    "def extract_sparql_query(entry):\n",
    "    raw_query = entry.get(\"sparql_query_kg2\", \"\")\n",
    "    # Remove comments starting with `#` and clean up spaces\n",
    "    cleaned_query = re.sub(r\"#.*\", \"\", raw_query)  # Remove everything after `#` on each line\n",
    "    # Extract content between SPARQL code blocks (```sparql and ``` or similar markers)\n",
    "    match = re.search(r\"```sparql\\n(.*?)\\n```\", cleaned_query, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).replace(\"\\n\", \" \").strip()  # Remove newline characters and trim whitespace\n",
    "    return None\n",
    "\n",
    "# Extract SPARQL queries\n",
    "queries_with_context = []\n",
    "for entry in data:\n",
    "    sparql_query = extract_sparql_query(entry)\n",
    "    if sparql_query:\n",
    "        queries_with_context.append({\n",
    "            \"natural_language_question\": entry[\"context\"][\"natural_language_question\"],\n",
    "            \"sparql_query_kg2\": sparql_query\n",
    "        })\n",
    "\n",
    "# Save the extracted queries to a new JSON file\n",
    "output_file = \"mistral_wiki_trans_sparql_queries.json\"\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(queries_with_context, file, indent=4)\n",
    "\n",
    "print(f\"Cleaned and extracted data has been saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the SPARQL queries from LLM output for **lama-3.1-8b-instruct**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and extracted data has been saved to lama_wiki_trans_sparql_queries.json.\n"
     ]
    }
   ],
   "source": [
    "input_file_path = 'translated_llm_output_meta-llama-3.1-8b.json'\n",
    "output_file_path = 'lama_wiki_trans_sparql_queries.json'\n",
    "\n",
    "# Load the JSON file\n",
    "with open(input_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Function to extract and clean SPARQL queries\n",
    "def extract_and_clean_sparql_query(sparql_raw):\n",
    "    try:\n",
    "        # Match SPARQL code blocks or queries starting with SPARQL keywords\n",
    "        sparql_match = re.search(r\"```sparql\\s*(.*?)\\s*```|PREFIX.*?WHERE\\s*\\{.*?\\}\", sparql_raw, re.DOTALL)\n",
    "        if sparql_match:\n",
    "            # Extract the matched SPARQL query\n",
    "            query = sparql_match.group(1) or sparql_match.group(0)\n",
    "            # Clean query by removing comments and excessive whitespace\n",
    "            query = re.sub(r\"#.*\", \"\", query)  # Remove comments\n",
    "            query = re.sub(r\"\\s+\", \" \", query).strip()  # Remove excessive whitespace and newlines\n",
    "            # Remove surrounding ```sparql and ```\n",
    "            query = query.replace(\"```sparql\", \"\").replace(\"```\", \"\").strip()\n",
    "            return query\n",
    "    except Exception as e:\n",
    "        print(f\"Error cleaning SPARQL query: {e}\")\n",
    "    return None\n",
    "\n",
    "# Process all entries and keep natural language question with the query\n",
    "result = []\n",
    "for entry in data:  # Process all entries\n",
    "    context = entry.get('context', {})\n",
    "    natural_language_question = context.get('natural_language_question', None)\n",
    "    sparql_query_raw = entry.get('sparql_query_kg2', '')\n",
    "\n",
    "    # Extract and clean the SPARQL query\n",
    "    sparql_query = extract_and_clean_sparql_query(sparql_query_raw)\n",
    "\n",
    "    if natural_language_question and sparql_query:\n",
    "        result.append({\n",
    "            \"natural_language_question\": natural_language_question,\n",
    "            \"sparql_query\": sparql_query\n",
    "        })\n",
    "\n",
    "# Save the cleaned and extracted data to a new JSON file\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    json.dump(result, output_file, indent=4)\n",
    "\n",
    "print(f\"Cleaned and extracted data has been saved to {output_file_path}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the extracted SPARQL queries on Wikidata\n",
    "Results for **mistral-large-instruct**.\n",
    "\n",
    "5 Queries are not working, because the syntax is not correct, probably because the extraction process did not work accuratly. Could probably be fixed by manual adjustments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: QueryBadFormed: A bad request has been sent to the endpoint: probably the SPARQL query is badly formed. \n",
      "\n",
      "Response:\n",
      "b'{\\n    \"exception\": \"Invalid SPARQL query: Prefix wikibase was not registered using a PREFIX declaration\",\\n    \"metadata\": {\\n        \"line\": 1,\\n        \"positionInLine\": 263,\\n        \"query\": \"PREFIX wd: <http://www.wikidata.org/entity/> PREFIX wdt: <http://www.wikidata.org/prop/direct/>  SELECT DISTINCT ?mountain ?mountainLabel ?elevation WHERE {   ?mountain wdt:P31 wd:Q8502 ;             wdt:P131 wd:Q38 ;             wdt:P2044 ?elevation .   SERVICE wikibase:label { bd:serviceParam wikibase:language \\\\\"[AUTO_LANGUAGE],en\\\\\". } } ORDER BY DESC(?elevation) LIMIT 1\",\\n        \"startIndex\": 263,\\n        \"stopIndex\": 276\\n    },\\n    \"query\": \"PREFIX wd: <http://www.wikidata.org/entity/> PREFIX wdt: <http://www.wikidata.org/prop/direct/>  SELECT DISTINCT ?mountain ?mountainLabel ?elevation WHERE {   ?mountain wdt:P31 wd:Q8502 ;             wdt:P131 wd:Q38 ;             wdt:P2044 ?elevation .   SERVICE wikibase:label { bd:serviceParam wikibase:language \\\\\"[AUTO_LANGUAGE],en\\\\\". } } ORDER BY DESC(?elevation) LIMIT 1\",\\n    \"resultsize\": 0,\\n    \"status\": \"ERROR\",\\n    \"time\": {\\n        \"computeResult\": 4,\\n        \"total\": 4\\n    }\\n}'\n",
      "Query failed: QueryBadFormed: A bad request has been sent to the endpoint: probably the SPARQL query is badly formed. \n",
      "\n",
      "Response:\n",
      "b'{\\n    \"exception\": \"Invalid SPARQL query: Token \\\\\"<\\\\\": no viable alternative at input \\'PREFIXwd:<http://www.wikidata.org/entity/>PREFIXwdt:<http://www.wikidata.org/prop/direct/>PREFIXwikibase:<\\'\",\\n    \"metadata\": {\\n        \"line\": 1,\\n        \"positionInLine\": 113,\\n        \"query\": \"PREFIX wd: <http://www.wikidata.org/entity/> PREFIX wdt: <http://www.wikidata.org/prop/direct/> PREFIX wikibase: <http://wikiba.se/ontology  SELECT DISTINCT ?country ?countryLabel WHERE {   wd:Q513 wdt:P131 ?country .   ?country wdt:P31 wd:Q6256 .   SERVICE wikibase:label { bd:serviceParam wikibase:language \\\\\"[AUTO_LANGUAGE],en\\\\\". } }\",\\n        \"startIndex\": 113,\\n        \"stopIndex\": 113\\n    },\\n    \"query\": \"PREFIX wd: <http://www.wikidata.org/entity/> PREFIX wdt: <http://www.wikidata.org/prop/direct/> PREFIX wikibase: <http://wikiba.se/ontology  SELECT DISTINCT ?country ?countryLabel WHERE {   wd:Q513 wdt:P131 ?country .   ?country wdt:P31 wd:Q6256 .   SERVICE wikibase:label { bd:serviceParam wikibase:language \\\\\"[AUTO_LANGUAGE],en\\\\\". } }\",\\n    \"resultsize\": 0,\\n    \"status\": \"ERROR\",\\n    \"time\": {\\n        \"computeResult\": 0,\\n        \"total\": 0\\n    }\\n}'\n",
      "Query failed: QueryBadFormed: A bad request has been sent to the endpoint: probably the SPARQL query is badly formed. \n",
      "\n",
      "Response:\n",
      "b'{\\n    \"exception\": \"Invalid SPARQL query: Token \\\\\"<\\\\\": no viable alternative at input \\'PREFIXwd:<http://www.wikidata.org/entity/>PREFIXwdt:<http://www.wikidata.org/prop/direct/>PREFIXwikibase:<\\'\",\\n    \"metadata\": {\\n        \"line\": 1,\\n        \"positionInLine\": 113,\\n        \"query\": \"PREFIX wd: <http://www.wikidata.org/entity/> PREFIX wdt: <http://www.wikidata.org/prop/direct/> PREFIX wikibase: <http://wikiba.se/ontology  SELECT DISTINCT ?uri WHERE {   ?uri wdt:P31 wd:Q5 ;         wdt:P19 wd:Q160544 . }\",\\n        \"startIndex\": 113,\\n        \"stopIndex\": 113\\n    },\\n    \"query\": \"PREFIX wd: <http://www.wikidata.org/entity/> PREFIX wdt: <http://www.wikidata.org/prop/direct/> PREFIX wikibase: <http://wikiba.se/ontology  SELECT DISTINCT ?uri WHERE {   ?uri wdt:P31 wd:Q5 ;         wdt:P19 wd:Q160544 . }\",\\n    \"resultsize\": 0,\\n    \"status\": \"ERROR\",\\n    \"time\": {\\n        \"computeResult\": 0,\\n        \"total\": 0\\n    }\\n}'\n",
      "Query failed: QueryBadFormed: A bad request has been sent to the endpoint: probably the SPARQL query is badly formed. \n",
      "\n",
      "Response:\n",
      "b'{\\n    \"exception\": \"Invalid SPARQL query: Prefix wikibase was not registered using a PREFIX declaration\",\\n    \"metadata\": {\\n        \"line\": 1,\\n        \"positionInLine\": 186,\\n        \"query\": \"PREFIX wd: <http://www.wikidata.org/entity/> PREFIX wdt: <http://www.wikidata.org/prop/direct/>  SELECT DISTINCT ?holiday ?holidayLabel WHERE {   ?holiday wdt:P31 wd:Q1445650.   SERVICE wikibase:label { bd:serviceParam wikibase:language \\\\\"[AUTO_LANGUAGE],en\\\\\". } }\",\\n        \"startIndex\": 186,\\n        \"stopIndex\": 199\\n    },\\n    \"query\": \"PREFIX wd: <http://www.wikidata.org/entity/> PREFIX wdt: <http://www.wikidata.org/prop/direct/>  SELECT DISTINCT ?holiday ?holidayLabel WHERE {   ?holiday wdt:P31 wd:Q1445650.   SERVICE wikibase:label { bd:serviceParam wikibase:language \\\\\"[AUTO_LANGUAGE],en\\\\\". } }\",\\n    \"resultsize\": 0,\\n    \"status\": \"ERROR\",\\n    \"time\": {\\n        \"computeResult\": 1,\\n        \"total\": 1\\n    }\\n}'\n",
      "Query failed: QueryBadFormed: A bad request has been sent to the endpoint: probably the SPARQL query is badly formed. \n",
      "\n",
      "Response:\n",
      "b'{\\n    \"exception\": \"Invalid SPARQL query: Token \\\\\"<\\\\\": no viable alternative at input \\'PREFIXwd:<http://www.wikidata.org/entity/>PREFIXwdt:<http://www.wikidata.org/prop/direct/>PREFIXrdfs:<\\'\",\\n    \"metadata\": {\\n        \"line\": 1,\\n        \"positionInLine\": 109,\\n        \"query\": \"PREFIX wd: <http://www.wikidata.org/entity/> PREFIX wdt: <http://www.wikidata.org/prop/direct/> PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema  SELECT DISTINCT ?holiday ?holidayLabel WHERE {   ?holiday wdt:P31 wd:Q1445650.   SERVICE wikibase:label { bd:serviceParam wikibase:language \\\\\"[AUTO_LANGUAGE],en\\\\\". } }\",\\n        \"startIndex\": 109,\\n        \"stopIndex\": 109\\n    },\\n    \"query\": \"PREFIX wd: <http://www.wikidata.org/entity/> PREFIX wdt: <http://www.wikidata.org/prop/direct/> PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema  SELECT DISTINCT ?holiday ?holidayLabel WHERE {   ?holiday wdt:P31 wd:Q1445650.   SERVICE wikibase:label { bd:serviceParam wikibase:language \\\\\"[AUTO_LANGUAGE],en\\\\\". } }\",\\n    \"resultsize\": 0,\\n    \"status\": \"ERROR\",\\n    \"time\": {\\n        \"computeResult\": 0,\\n        \"total\": 0\\n    }\\n}'\n",
      "Query results saved to wikidata_query_results_mistral.json.\n",
      "Total Queries: 99\n",
      "Successful Queries: 77\n",
      "Failed Queries: 5\n",
      "No Answer Queries: 17\n",
      "Accuracy: 77.78%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# File paths\n",
    "input_file_path = \"mistral_wiki_trans_sparql_queries.json\"\n",
    "output_file_path = \"wikidata_query_results_mistral.json\"\n",
    "\n",
    "# Wikidata local endpoint\n",
    "WIKIDATA_ENDPOINT = \"http://localhost:7001\"\n",
    "\n",
    "# Define prefixes for the queries\n",
    "PREFIXES = \"\"\"\n",
    "PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
    "PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX p: <http://www.wikidata.org/prop/>\n",
    "PREFIX ps: <http://www.wikidata.org/prop/statement/>\n",
    "PREFIX pq: <http://www.wikidata.org/prop/qualifier/>\n",
    "\"\"\"\n",
    "\n",
    "# Function to check and prepend prefixes if not present\n",
    "def ensure_prefixes(query):\n",
    "    if not query.strip().startswith(\"PREFIX\"):\n",
    "        return PREFIXES + query\n",
    "    return query\n",
    "\n",
    "# Function to query the SPARQL endpoint\n",
    "def query_sparql(endpoint, query):\n",
    "    sparql = SPARQLWrapper(endpoint)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    sparql.setMethod('GET')\n",
    "    sparql.setTimeout(60)\n",
    "    \n",
    "    try:\n",
    "        return sparql.query().convert()  # Return results\n",
    "    except Exception as e:\n",
    "        print(f\"Query failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Extract the answers from the SPARQL query results\n",
    "def extract_answer(results):\n",
    "    if not results:\n",
    "        return [\"Query failed\"]\n",
    "    \n",
    "    if 'boolean' in results:\n",
    "        return [\"True\"] if results['boolean'] else [\"False\"]\n",
    "\n",
    "    answers = []\n",
    "    bindings = results.get('results', {}).get('bindings', [])\n",
    "    for binding in bindings:\n",
    "        for var_name in binding:\n",
    "            value = binding[var_name]['value']\n",
    "            answers.append(value)  # Append the value directly\n",
    "    return answers if answers else [\"No answer\"]\n",
    "\n",
    "# Load the input dataset\n",
    "with open(input_file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize results list\n",
    "query_results = []\n",
    "\n",
    "# Process each query in the dataset\n",
    "for entry in data:\n",
    "    question = entry.get(\"natural_language_question\", \"\")\n",
    "    sparql_query = entry.get(\"sparql_query_kg2\", \"\")\n",
    "    \n",
    "    if not sparql_query:\n",
    "        print(f\"No SPARQL query found for question: {question}\")\n",
    "        continue\n",
    "\n",
    "    # Ensure prefixes are included in the query\n",
    "    sparql_query_with_prefixes = ensure_prefixes(sparql_query)\n",
    "\n",
    "    # Execute the query on the Wikidata endpoint\n",
    "    results = query_sparql(WIKIDATA_ENDPOINT, sparql_query_with_prefixes)\n",
    "    extracted_answers = extract_answer(results)\n",
    "    \n",
    "    # Append the query results\n",
    "    query_results.append({\n",
    "        \"natural_language_question\": question,\n",
    "        \"sparql_query\": sparql_query_with_prefixes,\n",
    "        \"answers\": extracted_answers\n",
    "    })\n",
    "\n",
    "# Save the results to a JSON file\n",
    "with open(output_file_path, \"w\") as output_file:\n",
    "    json.dump(query_results, output_file, indent=4)\n",
    "\n",
    "print(f\"Query results saved to {output_file_path}.\")\n",
    "\n",
    "# Calculate accuracy and categorize results\n",
    "total_queries = len(data)\n",
    "successful_queries = sum(1 for result in query_results if \"No answer\" not in result[\"answers\"] and \"Query failed\" not in result[\"answers\"])\n",
    "failed_queries = sum(1 for result in query_results if \"Query failed\" in result[\"answers\"])\n",
    "no_answer_queries = sum(1 for result in query_results if \"No answer\" in result[\"answers\"])\n",
    "accuracy = (successful_queries / total_queries) * 100 if total_queries > 0 else 0\n",
    "\n",
    "print(f\"Total Queries: {total_queries}\")\n",
    "print(f\"Successful Queries: {successful_queries}\")\n",
    "print(f\"Failed Queries: {failed_queries}\")\n",
    "print(f\"No Answer Queries: {no_answer_queries}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Visualize results with a bar chart\n",
    "categories = ['Successful Queries', 'Failed Queries', 'No Answer Queries']\n",
    "counts = [successful_queries, failed_queries, no_answer_queries]\n",
    "colors = ['green', 'red', 'orange']\n",
    "\n",
    "plt.bar(categories, counts, color=colors)\n",
    "plt.title('Query Results Analysis')\n",
    "plt.ylabel('Number of Queries')\n",
    "plt.xlabel('Query Outcome')\n",
    "for i, count in enumerate(counts):\n",
    "    plt.text(i, count + 0.5, str(count), ha='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results for **lama-3.1-8b-instruct**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further steps\n",
    "- Test the results for lama-3.1-8b-instruct \n",
    "- Compare both results\n",
    "- Compare the answers if the are matching with the original dataset\n",
    "- Test the results for mistral-large-instruct and lama-3.1-8b-instruct with the new query template and see if its easier to extract the queries and more accurate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
